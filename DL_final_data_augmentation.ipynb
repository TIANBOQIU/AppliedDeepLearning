{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_final_data_augmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TIANBOQIU/AppliedDeepLearning/blob/master/DL_final_data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGanCdWZZnv5",
        "colab_type": "code",
        "outputId": "a18c4e0b-53cb-4d69-c1a3-f641cf70bad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "!apt-get install -q openslide-tools\n",
        "!apt-get install -q rsync\n",
        "!pip install openslide-python\n",
        "!pip install tensorflow-gpu==2.0.0-alpha\n",
        "!pip install -q scikit-plot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "openslide-tools is already the newest version (3.4.1+dfsg-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "rsync is already the newest version (3.1.2-2.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from openslide-python) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->openslide-python) (0.46)\n",
            "Requirement already satisfied: tensorflow-gpu==2.0.0-alpha in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.1.6)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.14.0a20190301)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.0.9)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.16.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (3.7.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.33.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha) (3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaP8j0bhZ-So",
        "colab_type": "code",
        "outputId": "f3ed9ac9-d8a4-44b7-eba8-43ccb01f3ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os, random, re, time, shutil\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "import scikitplot as skplt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers, layers, models\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQn5P9H8aGvh",
        "colab_type": "code",
        "outputId": "1efd3858-aa64-4a03-fa94-ec7f941c9e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woJ8ACmybYy6",
        "colab_type": "text"
      },
      "source": [
        "###Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anG7SaK5a4VS",
        "colab_type": "text"
      },
      "source": [
        "utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hhByDTPaMLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "    im = slide.read_region((x,y), level, (width, height))\n",
        "    im = im.convert('RGB') # drop the alpha channel\n",
        "    if as_float:\n",
        "        im = np.asarray(im, dtype=np.float32)\n",
        "    else:\n",
        "        im = np.asarray(im)\n",
        "    assert im.shape == (height, width, 3)\n",
        "    return im\n",
        "\n",
        "def find_tumor_pixels(m):\n",
        "  return [(j, i) for i, row in enumerate(m)\n",
        "              for j, c in enumerate(row) if c]\n",
        "\n",
        "def find_tissue_pixels(s, intensity=0.8):\n",
        "  s_gray = rgb2gray(s)\n",
        "  idx = np.where(s_gray <= intensity)\n",
        "  return zip(idx[1], idx[0])\n",
        "\n",
        "def _get_helper(slide_path, mask_path):\n",
        "  slide, mask = open_slide(slide_path), open_slide(mask_path)\n",
        "  s = read_slide(slide, x=0, y=0, level=7, width=slide.level_dimensions[7][0], height=slide.level_dimensions[7][1])\n",
        "  m = read_slide(mask, x=0, y=0, level=7, width=mask.level_dimensions[7][0], height=mask.level_dimensions[7][1])[:,:,0]\n",
        "  return slide, mask, s, m\n",
        "\n",
        "def _get_locs(slide_path, mask_path):\n",
        "  slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "  loc_tissue = set(find_tissue_pixels(s))\n",
        "  loc_tumor = set(find_tumor_pixels(m))\n",
        "  loc_normal = loc_tissue - loc_tumor\n",
        "  return loc_tissue, loc_tumor, loc_normal\n",
        "\n",
        "def get_patch(slide, x, y, width, height):\n",
        "  patch = read_slide(slide, x=x, y=y, level=0, width=width, height=height)\n",
        "  return patch\n",
        "\n",
        "def _print_slide(slide_path, sz=10):\n",
        "  mask_path = slide_path.split('.')[0] + '_mask.tif'\n",
        "  slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "  plt.figure(figsize=(sz, sz))\n",
        "  plt.imshow(s)\n",
        "  plt.imshow(m, cmap='jet', alpha=0.5)\n",
        "  plt.title(slide_path.split('/')[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWWEjQ53a9tJ",
        "colab_type": "text"
      },
      "source": [
        "functions for fetching data and extracting patches "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkFd6IHpaWGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _myFetch(filenames):\n",
        "  if not os.path.exists('slides'):\n",
        "    os.mkdir('slides')\n",
        "  _root = '/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_slides'\n",
        "  for filename in filenames:\n",
        "    slide_path = os.path.join(_root, 'Copy of ' + filename)\n",
        "    mask_path = os.path.join(_root, 'Copy of ' + filename.split('.')[0]+'_mask.tif')\n",
        "    print('fetching %s ..' %filename)\n",
        "    shutil.copyfile(slide_path, 'slides/'+filename)\n",
        "    shutil.copyfile(mask_path, 'slides/'+filename.split('.')[0]+'_mask.tif')\n",
        "  \n",
        "  \n",
        "\n",
        "def _extract_tumor_slides(filenames):\n",
        "  if not os.path.exists('patches'):\n",
        "    os.mkdir('patches')\n",
        "  if not os.path.exists('patches/tumor'):\n",
        "    os.mkdir('patches/tumor')\n",
        "  if not os.path.exists('patches/normal'):\n",
        "    os.mkdir('patches/normal')\n",
        "  slides = ['slides/%s' %filename for filename in filenames]\n",
        "  masks = [path.split('.')[0]+'_mask.tif' for path in slides]\n",
        "  for slide_path, mask_path in zip(slides, masks):\n",
        "    slide_name = slide_path.split('/')[-1].split('.')[0]\n",
        "    slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "    loc_tissue, loc_tumor, loc_normal = _get_locs(slide_path, mask_path)\n",
        "    THRESH = len(loc_tumor) // 3\n",
        "    _num_tumor, _num_normal = 0, 0\n",
        "    \n",
        "    samples = random.sample(loc_tumor, THRESH)\n",
        "  \n",
        "    for x, y in samples:\n",
        "      if get_patch(mask, x*128, y*128, 128, 128)[:,:,0].any(): # is tumor\n",
        "        patch = get_patch(slide, max(0, x*128-85), max(0, y*128-85), 299, 299) # extract the context\n",
        "        img = Image.fromarray(patch, 'RGB')\n",
        "        img.save('patches/tumor/{}_{}_{}.png'.format(slide_name, x, y))\n",
        "        _num_tumor += 1\n",
        "    \n",
        "    samples = random.sample(loc_normal, _num_tumor//2)\n",
        "    for x, y in samples:\n",
        "      if not get_patch(mask, x*128, y*128, 128, 128)[:,:,0].any(): # is normal\n",
        "        patch = get_patch(slide, max(0, x*128-85), max(0, y*128-85), 299, 299)\n",
        "        img = Image.fromarray(patch, 'RGB')\n",
        "        img.save('patches/normal/{}_{}_{}.png'.format(slide_name, x, y))\n",
        "        _num_normal += 1\n",
        "    print('extracted: {:>20} ||  tumor patches {:<7} || normal patches {:<7}'.format(slide_name, _num_tumor, _num_normal))  \n",
        "    \n",
        "def _extract_normal_slides(filenames, THRESH):\n",
        "  if not os.path.exists('patches'):\n",
        "    os.mkdir('patches')\n",
        "  if not os.path.exists('patches/tumor'):\n",
        "    os.mkdir('patches/tumor')\n",
        "  if not os.path.exists('patches/normal'):\n",
        "    os.mkdir('patches/normal')\n",
        "  slides = ['slides/%s' %filename for filename in filenames]\n",
        "  masks = [path.split('.')[0]+'_mask.tif' for path in slides]\n",
        "  for slide_path, mask_path in zip(slides, masks):\n",
        "    slide_name = slide_path.split('/')[-1].split('.')[0]\n",
        "    slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "    loc_tissue, loc_tumor, loc_normal = _get_locs(slide_path, mask_path)\n",
        "    \n",
        "    _num_normal = 0\n",
        "    samples = random.sample(loc_normal, min(THRESH, len(loc_normal)))\n",
        "    for x, y in samples:\n",
        "      if not get_patch(mask, x*128, y*128, 128, 128)[:,:,0].any(): # is normal\n",
        "        patch = get_patch(slide, max(0, x*128-85), max(0, y*128-85), 299, 299)\n",
        "        img = Image.fromarray(patch, 'RGB')\n",
        "        img.save('patches/normal/{}_{}_{}.png'.format(slide_name, x, y))\n",
        "        _num_normal += 1\n",
        "    print('extracted: {:>20} ||  tumor patches {:<7} || normal patches {:<7}'.format(slide_name, 0, _num_normal))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq5yaLX1bMbH",
        "colab_type": "text"
      },
      "source": [
        "functions for creating, testing, and evaluating models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXGXGWTaYbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  conv_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "  model = models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  conv_base.trainable = False\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "def test_model(filename, model):\n",
        "  slide_path = 'slides/' + filename\n",
        "  mask_path = 'slides/' + filename.split('.')[0] + '_mask.tif'\n",
        "  slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "  loc_tissue, loc_tumor, loc_normal = _get_locs(slide_path, mask_path)\n",
        "  print('predicting on %i tissues' %len(loc_tissue))\n",
        "  s_mask = np.zeros(shape=m.shape, dtype=float)\n",
        "  i = 1\n",
        "  for x, y in loc_tissue:\n",
        "    if i % 2000 == 0:\n",
        "      print('predicting {:>7} / {} || {:<4f} %'.format(i, len(loc_tissue), 100 * i / len(loc_tissue)))\n",
        "    patch = get_patch(slide, max(0, x*128-85), max(0, y*128-85), 299, 299) # needs to normalize\n",
        "    patch = patch / 255\n",
        "    patch = np.expand_dims(patch, axis=0)\n",
        "    pred = model.predict(patch)\n",
        "    s_mask[y][x] = pred[0][0]\n",
        "    i += 1\n",
        "  return s_mask\n",
        "\n",
        "def test_model_in_parts(filename, model, _slice):\n",
        "  slide_path = 'slides/' + filename\n",
        "  mask_path = 'slides/' + filename.split('.')[0] + '_mask.tif'\n",
        "  slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "  loc_tissue, loc_tumor, loc_normal = _get_locs(slide_path, mask_path)\n",
        "  print('predicting on %i tissues' %len(loc_tissue))\n",
        "  s_mask = np.zeros(shape=m.shape, dtype=float)\n",
        "  i = 1\n",
        "  for x, y in list(loc_tissue)[_slice]:\n",
        "    if i % 2000 == 0:\n",
        "      print('predicting {:>7} / {} || {:<4f} %'.format(i, len(loc_tissue), 100 * i / len(loc_tissue)))\n",
        "    patch = get_patch(slide, max(0, x*128-85), max(0, y*128-85), 299, 299) # needs to normalize\n",
        "    patch = patch / 255\n",
        "    patch = np.expand_dims(patch, axis=0)\n",
        "    pred = model.predict(patch)\n",
        "    s_mask[y][x] = pred[0][0]\n",
        "    i += 1\n",
        "  return s_mask\n",
        "\n",
        "def _print_test(filename, s_mask):\n",
        "  slide_path, mask_path = 'slides/'+filename, 'slides/'+filename.split('.')[0]+'_mask.tif'\n",
        "  slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "  plt.figure(figsize=(20, 20))\n",
        "  plt.title(filename)\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(s)\n",
        "  plt.imshow(m, cmap='jet', alpha=0.5)\n",
        "  plt.title('ground truth')\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(s)\n",
        "  plt.imshow(s_mask, cmap='jet', alpha=0.5)\n",
        "  plt.title('predicted heatmap')\n",
        "  \n",
        "def _plot_auc(filename, s_mask):\n",
        "  slide_path, mask_path = 'slides/'+filename, 'slides/'+filename.split('.')[0]+'_mask.tif'\n",
        "  slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "  y_true = m.reshape((-1,))\n",
        "  y_tumor = s_mask.reshape((-1,))\n",
        "  y_normal = 1 - y_tumor\n",
        "  y_probas = np.array(list(zip(y_normal, y_tumor)))\n",
        "  skplt.metrics.plot_roc_curve(y_true, y_probas)\n",
        "  plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPsAAz-CbcKG",
        "colab_type": "text"
      },
      "source": [
        "###Training\n",
        "**fetching slides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLb0szAha1qP",
        "colab_type": "code",
        "outputId": "276b6c19-9978-4856-e66c-122c08a3dcad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "USER_NAME = \"tianboqiu\"\n",
        "USER_EMAIL = \"tianbo@gmail.com\"\n",
        "TOKEN = \"f949dc950a158c383ae842980e32030bafcb292a\"\n",
        "\n",
        "\n",
        "!git config --global user.email {USER_EMAIL}\n",
        "!git config --global user.name {USER_NAME}\n",
        "\n",
        "\n",
        "repo_path = \"DL_final\"\n",
        "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
        "  !git clone https://{USER_NAME}:{TOKEN}@github.com/TIANBOQIU/DL_final.git\n",
        "      \n",
        "\n",
        "os.chdir(repo_path) # change directory to the cloned repo\n",
        "!git pull\n",
        "\n",
        "#!git add .\n",
        "#!git commit -m \"commmit message\"\n",
        "#!git push https://{USER_NAME}:{TOKEN}@github.com/TIANBOQIU/DL_final.git master      "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A11DtHkGbqYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tumor_slides = ['tumor_016.tif', 'tumor_031.tif', 'tumor_064.tif',\n",
        "                'tumor_078.tif', 'tumor_084.tif', 'tumor_091.tif',\n",
        "                'tumor_094.tif', 'tumor_101.tif', 'tumor_110.tif']\n",
        "normal_slides = ['tumor_002.tif', 'tumor_012.tif', 'tumor_035.tif',\n",
        "                 'tumor_057.tif', 'tumor_059.tif', 'tumor_081.tif']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFcJfHz5bsyo",
        "colab_type": "code",
        "outputId": "4b71509a-1284-419f-8508-ad695ab566c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "# fetch slides of interest, which takes about 5 min\n",
        "_myFetch(tumor_slides+normal_slides)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fetching tumor_016.tif ..\n",
            "fetching tumor_031.tif ..\n",
            "fetching tumor_064.tif ..\n",
            "fetching tumor_078.tif ..\n",
            "fetching tumor_084.tif ..\n",
            "fetching tumor_091.tif ..\n",
            "fetching tumor_094.tif ..\n",
            "fetching tumor_101.tif ..\n",
            "fetching tumor_110.tif ..\n",
            "fetching tumor_002.tif ..\n",
            "fetching tumor_012.tif ..\n",
            "fetching tumor_035.tif ..\n",
            "fetching tumor_057.tif ..\n",
            "fetching tumor_059.tif ..\n",
            "fetching tumor_081.tif ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI0Pc2ZUfCaL",
        "colab_type": "text"
      },
      "source": [
        "**sampling, get balanced training patches**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbOLFi57buuF",
        "colab_type": "code",
        "outputId": "9456c921-ac53-4911-e27a-27bb54d17c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "print('THRESH = 1/3 loc_tummor, extract THRESH / 3 tumor patches, THRESH / 6 normal patches')\n",
        "for filename in tumor_slides:\n",
        "\n",
        "  slide_path, mask_path = 'slides/'+filename, 'slides/'+filename.split('.')[0]+'_mask.tif'\n",
        "  slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "  loc_tissue, loc_tumor, loc_normal = _get_locs(slide_path, mask_path)\n",
        "  print('\\t{} || tissue {:<7}  ||  tumor  {:>7}  ||  normal  {:>7}'.format(filename, len(loc_tissue), len(loc_tumor), len(loc_normal)))\n",
        "print('\\nevenly sample normal patches from normal slides, balance the tumor patches')\n",
        "for filename in normal_slides:\n",
        "\n",
        "  slide_path, mask_path = 'slides/'+filename, 'slides/'+filename.split('.')[0]+'_mask.tif'\n",
        "  slide, mask, s, m = _get_helper(slide_path, mask_path)\n",
        "  loc_tissue, loc_tumor, loc_normal = _get_locs(slide_path, mask_path)\n",
        "  print('\\t{} || tissue {:<7}  ||  tumor  {:>7}  ||  normal  {:>7}'.format(filename, len(loc_tissue), len(loc_tumor), len(loc_normal)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "THRESH = 1/3 loc_tummor, extract THRESH / 3 tumor patches, THRESH / 6 normal patches\n",
            "\ttumor_016.tif || tissue 71958    ||  tumor     9811  ||  normal    62203\n",
            "\ttumor_031.tif || tissue 46986    ||  tumor     7602  ||  normal    39423\n",
            "\ttumor_064.tif || tissue 65796    ||  tumor     8159  ||  normal    58875\n",
            "\ttumor_078.tif || tissue 215836   ||  tumor    59291  ||  normal   156554\n",
            "\ttumor_084.tif || tissue 86562    ||  tumor     1994  ||  normal    84571\n",
            "\ttumor_091.tif || tissue 62589    ||  tumor     2924  ||  normal    59667\n",
            "\ttumor_094.tif || tissue 155404   ||  tumor     3833  ||  normal   151571\n",
            "\ttumor_101.tif || tissue 150818   ||  tumor    11756  ||  normal   139078\n",
            "\ttumor_110.tif || tissue 137357   ||  tumor    64266  ||  normal    73124\n",
            "\n",
            "evenly sample normal patches from normal slides, balance the tumor patches\n",
            "\ttumor_002.tif || tissue 58873    ||  tumor       61  ||  normal    58826\n",
            "\ttumor_012.tif || tissue 84215    ||  tumor       72  ||  normal    84143\n",
            "\ttumor_035.tif || tissue 61831    ||  tumor       12  ||  normal    61819\n",
            "\ttumor_057.tif || tissue 55428    ||  tumor       76  ||  normal    55353\n",
            "\ttumor_059.tif || tissue 60777    ||  tumor       16  ||  normal    60761\n",
            "\ttumor_081.tif || tissue 96469    ||  tumor       30  ||  normal    96439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOvp3V2Qe_WP",
        "colab_type": "code",
        "outputId": "83f0ad8b-4bb8-4b51-e7b0-3577b556a20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "_extract_tumor_slides(tumor_slides) # takes about 50 min"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extracted:            tumor_016 ||  tumor patches 3270    || normal patches 1621   \n",
            "extracted:            tumor_031 ||  tumor patches 2534    || normal patches 1208   \n",
            "extracted:            tumor_064 ||  tumor patches 2719    || normal patches 1349   \n",
            "extracted:            tumor_078 ||  tumor patches 19763   || normal patches 9481   \n",
            "extracted:            tumor_084 ||  tumor patches 664     || normal patches 330    \n",
            "extracted:            tumor_091 ||  tumor patches 974     || normal patches 482    \n",
            "extracted:            tumor_094 ||  tumor patches 1277    || normal patches 637    \n",
            "extracted:            tumor_101 ||  tumor patches 3918    || normal patches 1951   \n",
            "extracted:            tumor_110 ||  tumor patches 21422   || normal patches 10332  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYbvuR4_fYD7",
        "colab_type": "code",
        "outputId": "c57ba8db-9161-4996-b935-15ba9bb30e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "_extract_normal_slides(normal_slides, 4858) # takes about 10 min"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extracted:            tumor_002 ||  tumor patches 0       || normal patches 4853   \n",
            "extracted:            tumor_012 ||  tumor patches 0       || normal patches 4857   \n",
            "extracted:            tumor_035 ||  tumor patches 0       || normal patches 4858   \n",
            "extracted:            tumor_057 ||  tumor patches 0       || normal patches 4851   \n",
            "extracted:            tumor_059 ||  tumor patches 0       || normal patches 4857   \n",
            "extracted:            tumor_081 ||  tumor patches 0       || normal patches 4857   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh8iFddry9wo",
        "colab_type": "text"
      },
      "source": [
        "**data augmentation**\n",
        "1. rotate the input patch by 4 multiplies of 90\n",
        "2. left-right flip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QyZ_4tQfZgz",
        "colab_type": "code",
        "outputId": "2a0c301d-6e3c-45c4-9e4c-4e2e8c9d11ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=180,\n",
        "                                   horizontal_flip=True\n",
        "                                  )\n",
        "# batch size is decreased from 32 to 8, otherwise the session will\n",
        "# run out of RAM and crash\n",
        "train_generator = train_datagen.flow_from_directory('patches', target_size=(299, 299), batch_size=8, class_mode='binary')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 113065 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SS_clC518wP",
        "colab_type": "code",
        "outputId": "790a81b7-766e-4133-d4f5-9a3dbdaf804f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_tumorSize = len(os.listdir('patches/tumor'))\n",
        "_normalSize = len(os.listdir('patches/normal'))\n",
        "print('training patches\\ttumor {:<7} ||  normal {:<7}'.format(_tumorSize, _normalSize))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training patches\ttumor 56541   ||  normal 56524  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuhiTaYS2Fmx",
        "colab_type": "text"
      },
      "source": [
        "**train a model from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGHggJaa2PKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_nopre():\n",
        "  conv_base = InceptionV3(weights=None, include_top=False, input_shape=(299, 299, 3))\n",
        "  model = models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKFfZKq63H9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model_nopre()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkKN3gLm3LTt",
        "colab_type": "code",
        "outputId": "98967e77-cef2-4f79-c45c-18414287f3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch=113101//8+1, epochs=1) # starts 1041"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14138/14138 [==============================] - 5978s 423ms/step - loss: 0.2920 - acc: 0.8985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6jBULPh5jvI",
        "colab_type": "text"
      },
      "source": [
        "*takes more than 200 min for one epoch, I think the session will be terminated for the long runtime. I will train it epoch by epoch after the session crash. needs to save checkpoints*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwgdMnEA5_Cg",
        "colab_type": "code",
        "outputId": "ab285a9d-5c99-4280-d2c7-58ceaf5a48e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if not os.path.exists('models'):\n",
        "  os.mkdir('models')\n",
        "model.save_weights('models/InceptionV3_nopre_checkpoint1')\n",
        "model.save('models/InceptionV3_nopre.h5')\n",
        "shutil.copytree('models', '/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_models/InceptionV3_nopre')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_models/InceptionV3_nopre'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhZdvA5lrV8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20e678a7-812c-467e-d5d7-7903b02935c8"
      },
      "source": [
        "save_dir = '/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_models/'\n",
        "!ls '/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_models/'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "InceptionV3_nopre  InceptionV3_pre  InceptionV3_pre_v3_0510_113074.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zpiwInMsQJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "db1e2842-e3b5-4322-d068-ec2776818a5c"
      },
      "source": [
        "!ls '/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_models/InceptionV3_nopre'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "InceptionV3_nopre_checkpoint1.data-00000-of-00001\n",
            "InceptionV3_nopre_checkpoint1.index\n",
            "InceptionV3_nopre.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUwovfk4sOMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aceb6b6b-5813-4cd6-bd84-f7abfea880f5"
      },
      "source": [
        "model = create_model_nopre()\n",
        "model.load_weights(os.path.join(save_dir, 'InceptionV3_nopre/InceptionV3_nopre_checkpoint1'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe5869a0240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZveCLv-s3tM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3db0b32b-8fa6-4b55-89c7-cf3d136e024d"
      },
      "source": [
        "history2 = model.fit_generator(train_generator, steps_per_epoch=113065//8+1, epochs=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14134/14134 [==============================] - 5934s 420ms/step - loss: 0.2110 - acc: 0.9415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aG8pO61LtPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74e5fb9b-d97e-42b0-ce48-b4d946826de5"
      },
      "source": [
        "if not os.path.exists('models'):\n",
        "  os.mkdir('models')\n",
        "model.save_weights('models/InceptionV3_nopre_checkpoint2')\n",
        "#model.save('models/InceptionV3_nopre_ck2.h5')\n",
        "shutil.copytree('models', '/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_models/InceptionV3_nopre_ck2')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_models/InceptionV3_nopre_ck2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erxzvLQWMGfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save('/content/gdrive/My Drive/DeepLearning/datasets/DL_final/my_models/InceptionV3_nopre_ck2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}